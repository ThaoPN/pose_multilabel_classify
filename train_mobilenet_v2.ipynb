{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Add\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 75\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "imagePaths = sorted(list(paths.list_images('./pose_dataset/train_set')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    # extract set of class labels from the image path and update the\n",
    "    # labels list\n",
    "    l = label = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n",
    "    len(imagePaths), data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "# loop over each of the possible class labels and show them\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label_details(labels):\n",
    "\n",
    "    print(len(labels))\n",
    "\n",
    "    count_h = 0\n",
    "    count_n = 0\n",
    "    count_bending = 0\n",
    "    count_couching = 0\n",
    "    count_others = 0\n",
    "    count_standing = 0\n",
    "    for label in labels:\n",
    "        if label[0] == 1:\n",
    "            count_bending += 1\n",
    "        if label[1] == 1:\n",
    "            count_couching += 1\n",
    "        if label[2] == 1:\n",
    "            count_h += 1\n",
    "        if label[3] == 1:\n",
    "            count_n += 1\n",
    "        if label[4] == 1:\n",
    "            count_others += 1\n",
    "        if label[5] == 1:\n",
    "            count_standing += 1\n",
    "\n",
    "    print(\"bending: {}\\ncrouching: {}\\n_h: {}\\n_n: {} \\nothers: {}\\nstanding: {}\".format(count_bending, count_couching, count_h, count_n, count_others, count_standing))\n",
    "\n",
    "print_label_details(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2_model = MobileNetV2(input_shape=IMAGE_DIMS, weights=None, include_top=False)\n",
    "mobilenetv2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mobilenetv2_model.input)\n",
    "print(mobilenetv2_model.layers[-1].output)\n",
    "print(mlb.classes_)\n",
    "\n",
    "# initialize the model using a sigmoid activation as the final layer\n",
    "# in the network so we can perform multi-label classification\n",
    "\n",
    "conv_model = Model(inputs=mobilenetv2_model.input,\n",
    "                   outputs=mobilenetv2_model.layers[-1].output)\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(conv_model)\n",
    "new_model.add(GlobalAveragePooling2D())\n",
    "new_model.add(Dense(len(mlb.classes_), activation='sigmoid'))\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0, random_state=42)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the optimizer (SGD is sufficient)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "# compile the model using binary cross-entropy rather than\n",
    "# categorical cross-entropy -- this may seem counterintuitive for\n",
    "# multi-label classification, but keep in mind that the goal here\n",
    "# is to treat each output label as an independent Bernoulli\n",
    "# distribution\n",
    "new_model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = new_model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = new_model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "new_model.save('pose_multi_labels_mobilenet_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open('mlb.pickle', \"wb\")\n",
    "f.write(pickle.dumps(mlb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('plot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username for 'https://github.com': "
     ]
    }
   ],
   "source": [
    "! git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
